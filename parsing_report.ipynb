{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from jaro import jaro_winkler_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only report chat\n",
    "df = pd.read_csv(\"assets/classifiedchat_context.csv\")\n",
    "cat_report = df[df['Category'] == 'report']\n",
    "\n",
    "def preprocessing_report(report):\n",
    "    # lowercase all messages\n",
    "    report = cat_report['Message'].str.lower()\n",
    "\n",
    "    # remove unwanted characters\n",
    "    report = report.str.replace('_', '').str.replace('`', '').str.replace('.', '').str.replace(',', '').str.replace('*', '').str.lstrip().str.rstrip()\n",
    "\n",
    "    # remove all emojis\n",
    "    emojis = pd.read_csv('assets/emojis.csv')\n",
    "    emojis_list = emojis['emo'].tolist()\n",
    "\n",
    "    for emoji in emojis_list:\n",
    "        report = report.str.replace(emoji, '')\n",
    "\n",
    "    # remove unwanted words\n",
    "    word_list = ['selesai', 'done']\n",
    "    for word in word_list:\n",
    "        report = report.str.replace(word, '')\n",
    "\n",
    "    # remove unknown characters\n",
    "    for i, message in enumerate(report):\n",
    "        modified_text = re.sub(r'(?<=\\D)(\\d+)', r' \\1', message)\n",
    "        modified_text = re.sub(r'(?<=\\d)([a-zA-Z])', r' \\1', modified_text)\n",
    "        report[i:i+1] = ' '.join(modified_text.split())\n",
    "    \n",
    "    return report\n",
    "\n",
    "report = preprocessing_report(cat_report)\n",
    "report.to_csv('assets/report.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_bookname_typo(report, booknames):\n",
    "    first_word_match = re.match(r'^\\w+', report)\n",
    "    if first_word_match:\n",
    "        first_word = first_word_match.group(0)\n",
    "    else:\n",
    "        first_word = ''\n",
    "    \n",
    "    rest_of_report = re.sub(r'^\\w+', '', report).lstrip()\n",
    "\n",
    "    match = re.search(r'-(\\s*\\b[a-zA-Z]+\\b|\\b[a-zA-Z]+\\b)', rest_of_report)\n",
    "    if match:\n",
    "        after_hyphen = match.group(1)\n",
    "        fixed_after_hyphen = fix_bookname(after_hyphen.strip(), booknames)\n",
    "        rest_of_report = rest_of_report.replace(after_hyphen, fixed_after_hyphen, 1)\n",
    "\n",
    "    return fix_bookname(first_word, booknames) + \" \" + rest_of_report.strip()\n",
    "\n",
    "def fix_bookname(bookname_input, booknames):\n",
    "    booknames_list = booknames[\"Kitab\"].tolist()\n",
    "\n",
    "    max_score = 0.75\n",
    "    current_bookname = bookname_input\n",
    "\n",
    "    for bookname in booknames_list:\n",
    "        similarity_score = jaro_winkler_metric(bookname_input, bookname)\n",
    "        if similarity_score > max_score:\n",
    "            max_score = similarity_score\n",
    "            current_bookname = bookname\n",
    "\n",
    "    return current_bookname\n",
    "\n",
    "report2 = pd.read_csv('assets/report.csv')\n",
    "booknames = pd.read_csv(\"assets/book_names.csv\")\n",
    "\n",
    "for i in range(len(report2)):\n",
    "    report2['Message'][i] = fix_bookname_typo(report2['Message'][i], booknames)\n",
    "\n",
    "report2.to_csv('assets/report2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_list = pd.read_csv('assets/book_names.csv')\n",
    "book_list = book_list['Kitab'].tolist()\n",
    "\n",
    "# Construct a regex pattern to match any of the names in the list along with numbers and '-'\n",
    "pattern = r'(?:\\b(?:' + '|'.join(book_list) + r')\\b(?:\\s*\\d*-*\\d*\\s*)*)'\n",
    "\n",
    "# Messages\n",
    "report3 = pd.read_csv('assets/report2.csv')\n",
    "processed_message = []\n",
    "\n",
    "for text in report3['Message']:\n",
    "    # Skip empty strings\n",
    "    if not text.strip():\n",
    "        continue\n",
    "    \n",
    "    # Find all matches for the pattern in the text\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    # Construct the final output by joining the matches\n",
    "    output = ' '.join(matches)\n",
    "    # Remove double spaces\n",
    "    output = ' '.join(output.split())\n",
    "\n",
    "    # Remove space before or after hyphen\n",
    "    output = re.sub(r'\\s*-\\s*', r'-', output)\n",
    "\n",
    "    processed_message.append(output)\n",
    "    \n",
    "dict_msg = {'processed': processed_message}\n",
    "\n",
    "# Create DataFrame excluding empty strings\n",
    "df = pd.DataFrame(dict_msg)\n",
    "\n",
    "# Drop rows with empty strings\n",
    "# df = df[df['processed'] != \"\"]\n",
    "df.to_csv('assets/cleaned_messages.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "singkatan_df = pd.read_csv('assets/singkatan.csv')\n",
    "kitab_df = pd.read_csv('assets/biblebooknames.csv')\n",
    "singkatan_dict = dict(zip(singkatan_df['Singkatan'], kitab_df['Kitab']))\n",
    "\n",
    "# Baca file cleaned_messages.csv\n",
    "cleaned_messages_df = pd.read_csv('assets/cleaned_messages.csv')\n",
    "\n",
    "# Fungsi untuk mengganti singkatan dengan nama lengkap\n",
    "def ganti_singkatan(text):\n",
    "    if isinstance(text, str):  # Check if text is a string\n",
    "        words = text.split()\n",
    "        for i, word in enumerate(words):\n",
    "            if '-' in word:\n",
    "                parts = word.split('-')\n",
    "                if len(parts) == 2 and parts[1] in singkatan_dict:\n",
    "                    parts[0] = singkatan_dict.get(parts[0], parts[0])\n",
    "                    parts[1] = singkatan_dict[parts[1]]\n",
    "                    words[i] = '-'.join(parts)\n",
    "            elif word in singkatan_dict:\n",
    "                words[i] = singkatan_dict[word]\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        return text  # If text is not a string (NaN), return it as is\n",
    "\n",
    "# Terapkan fungsi pada kolom 'processed' dan simpan kembali ke cleaned_messages.csv\n",
    "cleaned_messages_df['processed'] = cleaned_messages_df['processed'].apply(ganti_singkatan)\n",
    "cleaned_messages_df.to_csv('assets/cleaned_messages2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_chapter_range(input_str):\n",
    "    # Split the input string into book and chapter range\n",
    "    parts = str(input_str).split()\n",
    "    if len(parts) > 2:\n",
    "        book = parts[0] + \" \" + parts[1]\n",
    "        chapters = parts[2].split('-')\n",
    "    elif len(parts) < 2:\n",
    "        return input_str\n",
    "    else:\n",
    "        book = parts[0]\n",
    "        chapters = parts[1].split('-')\n",
    "\n",
    "    # If there's only one chapter, return the original input\n",
    "    if len(chapters) == 1:\n",
    "        return input_str\n",
    "\n",
    "    # Otherwise, format the output\n",
    "    start_chapter = chapters[0]\n",
    "    end_chapter = chapters[1]\n",
    "    output = f\"{book} {start_chapter} - {book} {end_chapter}\"\n",
    "    return output\n",
    "\n",
    "data = pd.read_csv(\"assets/cleaned_messages2.csv\")\n",
    "\n",
    "for i in range(len(data['processed'])):\n",
    "    data['processed'][i] = expand_chapter_range(data['processed'][i])\n",
    "\n",
    "data.to_csv('assets/cleaned_messages3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesan telah berhasil diparsing dan disimpan ke dalam file: assets/parsed_messages.csv\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk membaca jenis kejadian dan nomor kejadian dari file CSV\n",
    "def read_events(file_name):\n",
    "    events = []\n",
    "    with open(file_name, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            events.append(row[0].lower())  # Tambahkan jenis kejadian dengan nomor kejadian\n",
    "    return events\n",
    "\n",
    "# Fungsi untuk mengubah format pesan\n",
    "def parse_messages(file_name, events):\n",
    "    parsed_messages = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        matches = re.findall(r'(\\w+\\s\\d+)(?:\\s*-\\s*(\\w+\\s\\d+))?', line)\n",
    "        parsed_line = ''\n",
    "        for match in matches:\n",
    "            if match[1]:  # Memeriksa apakah ada rentang kejadian\n",
    "                start_event, end_event = match\n",
    "                start_index = events.index(start_event.lower())\n",
    "                end_index = events.index(end_event.lower())\n",
    "                for i in range(start_index, end_index + 1):\n",
    "                    parsed_line += f\"{events[i].capitalize()}, \"\n",
    "            else:  # Memeriksa apakah hanya satu kejadian\n",
    "                event_name = match[0]\n",
    "                event_index = events.index(event_name.lower())\n",
    "                parsed_line += f\"{events[event_index].capitalize()}, \"\n",
    "        parsed_line = parsed_line[:-2]  # Menghapus koma dan spasi ekstra dari akhir\n",
    "        parsed_messages.append(parsed_line + \"\\n\")\n",
    "\n",
    "    return parsed_messages\n",
    "\n",
    "# Fungsi untuk menyimpan hasil parsing ke file\n",
    "def save_parsed_messages(parsed_messages, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        for parsed_line in parsed_messages:\n",
    "            file.write(parsed_line)\n",
    "\n",
    "# Contoh penggunaan\n",
    "file_name = 'assets/biblechapters.csv'\n",
    "output_file = 'assets/parsed_messages.csv'\n",
    "\n",
    "events = read_events(file_name)\n",
    "parsed_messages = parse_messages('assets/cleaned_messages3.csv', events)\n",
    "save_parsed_messages(parsed_messages, output_file)\n",
    "print(\"Pesan telah berhasil diparsing dan disimpan ke dalam file:\", output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
