{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from jaro import jaro_winkler_metric\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"assets/classifiedchat_context.csv\")\n",
    "df = df[df['Category'] == 'report']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Bible verses (from Amsal 28:2 become Amsal 28)\n",
    "def remove_colon_number(text):\n",
    "    pattern = r\"\\s*:\\s*\\d+\"\n",
    "    return re.sub(pattern, \"\", text)\n",
    " \n",
    "df['Preprocessing1'] = df['Message'].apply(remove_colon_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting numbers with commas\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'(\\w+) (\\d+), (\\d+)-(\\d+)(?:\\s\\w+)*', r'\\1 \\2-\\4', text, flags=re.IGNORECASE)\n",
    "    return cleaned_text\n",
    "\n",
    "df['Preprocessing2'] = df['Preprocessing1'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted characters\n",
    "def remove_unwanted_char(text):\n",
    "    # lowercase all messages\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove unwanted characters\n",
    "    text = text.replace('_', '').replace('`', '').replace('.', '').replace('--', '-').replace(',', '').replace('*', '').replace('\"', '').lstrip().rstrip()\n",
    "\n",
    "    # remove all emojis\n",
    "    emojis = pd.read_csv('assets/emojis.csv')\n",
    "    emojis_list = emojis['emo'].tolist()\n",
    "\n",
    "    for emoji in emojis_list:\n",
    "        text = text.replace(emoji, '')\n",
    "\n",
    "    # remove unwanted words\n",
    "    word_list = ['selesai', 'done']\n",
    "    for word in word_list:\n",
    "        text = text.replace(word, '')\n",
    "\n",
    "    # remove unknown characters\n",
    "    modified_text = re.sub(r'(?<=\\D)(\\d+)', r' \\1', text)\n",
    "    modified_text = re.sub(r'(?<=\\d)([a-zA-Z])', r' \\1', modified_text)\n",
    "\n",
    "    # remove diacritic characters\n",
    "    cleaned_text = unidecode(' '.join(modified_text.split()))\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s-]', '', cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "df['Preprocessing3'] = df['Preprocessing2'].apply(remove_unwanted_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fromat series of numbers (from Amsal 28-29; 30-31; 32-33 become Amsal 28-33)\n",
    "# def format_numbers(report):\n",
    "#     pattern = r\"(\\d+)\\s*-\\s*(\\d+)(?:\\s*[,;]\\s*(\\d+)\\s*-\\s*(\\d+))*\\s*(?:done)?\"\n",
    "\n",
    "#     # Using re.findall() to find all patterns in the report\n",
    "#     matches = re.findall(pattern, report, re.IGNORECASE)\n",
    "\n",
    "#     # If a pattern is found\n",
    "#     if matches:\n",
    "#         # Initializing a list to store all numbers found\n",
    "#         all_numbers = []\n",
    "\n",
    "#         # Collecting all numbers from each found pattern\n",
    "#         for match in matches:\n",
    "#             for num in match:\n",
    "#                 if num:\n",
    "#                     all_numbers.append(int(num))\n",
    "\n",
    "#         # Sorting numbers and removing duplicates\n",
    "#         all_numbers = sorted(set(all_numbers))\n",
    "\n",
    "#         # Creating a range of numbers\n",
    "#         min_num = all_numbers[0]\n",
    "#         max_num = all_numbers[-1]\n",
    "\n",
    "#         # Taking the book name from the report\n",
    "#         book_name = re.search(r'^\\w+', report).group()\n",
    "\n",
    "#         # Generating the result string in the desired format\n",
    "#         result = f\"{book_name} {min_num}-{max_num}\"\n",
    "#         return result\n",
    "#     else:\n",
    "#         return report\n",
    "\n",
    "# df['Preprocessing'] = df['Preprocessing'].apply(format_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_numbers(report):\n",
    "    pattern = r\"(\\b\\w+\\b\\s+)?(\\d+)\\s*-\\s*(\\d+)(?:\\s*[,;]\\s*(\\d+)\\s*-\\s*(\\d+))*\\s*(?:done)?\"\n",
    "    # ^^^^^^^^^^^^^^^^\n",
    "\n",
    "    # Using re.findall() to find all patterns in the report\n",
    "    matches = re.findall(pattern, report, re.IGNORECASE)\n",
    "\n",
    "    # If a pattern is found\n",
    "    if matches:\n",
    "        # Initializing a list to store all numbers found\n",
    "        all_numbers = []\n",
    "\n",
    "        # Collecting all numbers from each found pattern\n",
    "        for match in matches:\n",
    "            for num in match[1:]:\n",
    "                if num:\n",
    "                    all_numbers.append(int(num))\n",
    "\n",
    "        # Sorting numbers and removing duplicates\n",
    "        all_numbers = sorted(set(all_numbers))\n",
    "\n",
    "        # Creating a range of numbers\n",
    "        min_num = all_numbers[0]\n",
    "        max_num = all_numbers[-1]\n",
    "\n",
    "        # Taking the book name from the report\n",
    "        book_name = match[0] if match[0] else re.search(r'^\\w+', report).group()\n",
    "\n",
    "        # Generating the result string in the desired format\n",
    "        result = f\"{book_name} {min_num}-{max_num}\"\n",
    "        return result\n",
    "    else:\n",
    "        return report\n",
    "\n",
    "df['Preprocessing4'] = df['Preprocessing3'].apply(format_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Preprocessing4'].to_csv('1Preprocessing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function corrects the typo in a given book name within a report.\n",
    "def fix_bookname_typo(report, booknames):\n",
    "    # Extracting the first word of the report\n",
    "    first_word_match = re.match(r'^\\w+', report)\n",
    "    if first_word_match:\n",
    "        first_word = first_word_match.group(0)\n",
    "    else:\n",
    "        first_word = ''  # Default value if no word is found\n",
    "       \n",
    "    # Removing the first word from the report\n",
    "    rest_of_report = re.sub(r'^\\w+', '', report).lstrip()\n",
    "\n",
    "    # Searching for a word following a hyphen in the remaining report\n",
    "    match = re.search(r'-(\\s*\\b[a-zA-Z]+\\b|\\b[a-zA-Z]+\\b)', rest_of_report)\n",
    "    if match:\n",
    "        after_hyphen = match.group(1)  # Word following the hyphen\n",
    "        # Fixing the typo in the word following the hyphen\n",
    "        fixed_after_hyphen = fix_bookname(after_hyphen.strip(), booknames)\n",
    "        # Replacing the original word with the corrected one\n",
    "        rest_of_report = rest_of_report.replace(after_hyphen, fixed_after_hyphen, 1)\n",
    "\n",
    "    # Fixing the typo in the first word of the report and returning the corrected report\n",
    "    output = fix_spaces(fix_bookname(first_word, booknames) + \" \" + rest_of_report.strip())\n",
    "    return ' '.join(output.split())\n",
    "\n",
    "# This function finds the closest match to a given book name from a list of book names.\n",
    "def fix_bookname(bookname_input, booknames):\n",
    "    booknames_list = booknames[\"Kitab\"].tolist()  # Converting book names to a list\n",
    "\n",
    "    max_score = 0.75  # Threshold for similarity score\n",
    "    current_bookname = bookname_input  # Default value is the input book name\n",
    "\n",
    "    # Iterating through the list of book names to find the closest match\n",
    "    for bookname in booknames_list:\n",
    "        similarity_score = jaro_winkler_metric(bookname_input, bookname)\n",
    "        if similarity_score >= max_score:\n",
    "            max_score = similarity_score\n",
    "            current_bookname = bookname\n",
    "\n",
    "    # Returning the closest match to the input book name\n",
    "    return current_bookname\n",
    "\n",
    "def fix_spaces(text):\n",
    "    # Using regular expression to find hyphens surrounded by spaces\n",
    "    fixed_text = re.sub(r'\\s*-\\s*', ' - ', text)\n",
    "    return fixed_text\n",
    "\n",
    "booknames_list = pd.read_csv(\"assets/book_names.csv\")\n",
    "\n",
    "df['Fix Book Name'] = df['Preprocessing4'].apply(lambda x: fix_bookname_typo(x, booknames_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fix Book Name'].to_csv('2Fix_Book_Name.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
